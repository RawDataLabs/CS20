{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.01 Manage Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 효율적인 방법으로 단어를 표시 하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 표현  \n",
    "\n",
    "각 단어를 하나의 Vector로 표현하며 해당 되는 것은 1이고 나머지는 0으로 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example   \n",
    "Vocab: i, it, california, meh  \n",
    "  \n",
    "i  = [1 0 0 0] ==> 첫번째 1 표시 나머지 0  \n",
    "it = [0 1 0 0] ==> 두번째 1 표시 나머지 0  \n",
    "california = [0 0 1 0] ==> 세번째 1 표시 나머지 0  \n",
    "meh = [0 0 0 1]==> 네번째 1 표시 나머지 0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어휘가 커지면 방대한 차원, 비효율적인 계산 발생 한다.  \n",
    "단어 간의 관계를 표현할 수 없다. => \"불안\"과 \"신경질적인\"은 유사하지만 완전히 다른 표현을 나타난다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding (One-hot 표현에 문제점을 해결)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산된 표현 방식    \n",
    "연속 값  \n",
    "방대한 차원 발생하지 않음    \n",
    "단어 사이의 의미론적관계 표현 가능  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법은 무엇인가 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing a word by means of its neighbors  \n",
    "“You shall know a word by the company it keeps.”  \n",
    "Firth, J. R. 1957:11  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 word2vec으로 표현 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count VS Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count (갯수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count를 기반으로 아래와 같은 표를 구성 할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공간에 표현하면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Word2Vec의 두가지 방법인 CBOW와 Skip-gram을 통해서 예측하는 방법을 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax vs 샘플 기반 접근법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 수식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 기반 접근법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Sampling (부정적인 샘플링)   \n",
    "Noise Contrastive Estimation  (소음 대비 평가)  \n",
    "\n",
    "\n",
    "NCE는 softmax에 근사값을 보장한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 색인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding lookup 함수  \n",
    "tf.nn.embedding_lookup(params, ids, partition_strategy='mod', name=None, validate_indices=True, max_norm=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCE Loss 함수  \n",
    "\n",
    "tf.nn.nce_loss(  \n",
    "    weights,  \n",
    "    biases,  \n",
    "    labels,  \n",
    "    inputs,  \n",
    "    num_sampled,  \n",
    "    num_classes,  \n",
    "    num_true=1,  \n",
    "    sampled_values=None,  \n",
    "    remove_accidental_hits=False,  \n",
    "    partition_strategy='mod',  \n",
    "    name='nce_loss'  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 링크 참조 https://github.com/changwookjun/CS20/blob/master/04.03%20Eager%20execution%20(Word2Vec).ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 모델 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 그래프를 조립한다.   \n",
    "    \n",
    "    1.1 데이터 가져 오기  \n",
    "    1.2 가중치 및 편향 정의  \n",
    "    1.3 추론 모델을 정의하라.  \n",
    "    1.4 손실 함수 정의  \n",
    "    1.5 최적화 도구 정의  \n",
    "2. 계산  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 링크 참조 https://github.com/changwookjun/CS20/blob/master/04.04%20Eager%20execution%20(Word2Vec%20Visualize).ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

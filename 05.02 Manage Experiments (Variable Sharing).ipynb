{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.02 Manage Experiments (Variable Sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow는 말할 때까지 어떤 노드를 함께 그룹화해야 할때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그룹 노드는 아래와 같이 작성하면 된다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(name_of_that_scope):  \n",
    "\tdeclare op_1  \n",
    "\tdeclare op_2  \n",
    "\t...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가변 범위는 변수 공유를 용이하게합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable sharing: The problem\n",
    "    \n",
    "def two_hidden_layers(x):\n",
    "    assert x.shape.as_list() == [200, 100]\n",
    "    w1 = tf.get_variable(\"h1_weights\", [100, 50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.get_variable(\"h1_biases\", [50], initializer=tf.constant_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "    assert h1.shape.as_list() == [200, 50]  \n",
    "    w2 = tf.get_variable(\"h2_weights\", [50, 10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.get_variable(\"h2_biases\", [10], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits\n",
    "\n",
    "logits1 = two_hidden_layers(x1)\n",
    "logits2 = two_hidden_layers(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 재 사용의 문제가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 해결 방법  \n",
    "1. 변수 h1_weights가 이미 존재하며 허용되지 않습니다. VarScope에서 reuse = True를 설정하는 방법  \n",
    "2. 변수를 범위에 넣고 해당 범위 내의 모든 변수를 다시 사용하면 된다. (아래와 같이)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_hidden_layers(x):\n",
    "    assert x.shape.as_list() == [200, 100]\n",
    "    w1 = tf.get_variable(\"h1_weights\", [100, 50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.get_variable(\"h1_biases\", [50], initializer=tf.constant_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "    assert h1.shape.as_list() == [200, 50]  \n",
    "    w2 = tf.get_variable(\"h2_weights\", [50, 10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.get_variable(\"h2_biases\", [10], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits\n",
    "with tf.variable_scope('two_layers') as scope:\n",
    "    logits1 = two_hidden_layers(x1)\n",
    "    scope.reuse_variables()\n",
    "    logits2 = two_hidden_layers(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Sharing 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JunChangWook/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.truncated_normal([200, 100], name='x1')\n",
    "x2 = tf.truncated_normal([200, 100], name='x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_hidden_layers(x):\n",
    "    assert x.shape.as_list() == [200, 100]\n",
    "    w1 = tf.Variable(tf.random_normal([100, 50]), name='h1_weights')\n",
    "    b1 = tf.Variable(tf.zeros([50]), name='h1_biases')\n",
    "    h1 = tf.matmul(x, w1) + b1   # `a` * `b`\n",
    "    assert h1.shape.as_list() == [200, 50]\n",
    "    w2 = tf.Variable(tf.random_normal([50, 10]), name='h2_weights')\n",
    "    b2 = tf.Variable(tf.zeros([10]), name='2_biases')\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_hidden_layers_2(x):\n",
    "    assert x.shape.as_list() == [200, 100]\n",
    "    w1 = tf.Variable('h1_weights', [100, 50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.Variable('h1_biases', [50], initializer=tf.random_normal_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "    assert h1.shape.as_list() == [200, 50]\n",
    "    w2 = tf.Variable('h2_weights', [50, 10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.Variable('h2_biases', [10], initializer=tf.random_normal_initializer())\n",
    "    logits = tf.matmul(h1, w2) + b2\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(x, output_dim, scope):\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope: # 재사용 가능 하게 추가 하였음\n",
    "        w = tf.get_variable('weights', [x.shape[1], output_dim], initializer=tf.random_normal_initializer())\n",
    "        b = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_hidden_layers(x):\n",
    "    h1 = fully_connected(x, 50, 'h1')\n",
    "    h2 = fully_connected(h1, 50, 'h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('two_layers') as scope:\n",
    "    logits1 = two_hidden_layers(x1)\n",
    "    logits2 = two_hidden_layers(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./graphs/cool_variables', tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits1 = two_hidden_layers(x1)\n",
    "logits2 = two_hidden_layers(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits1 = two_hidden_layers_2(x1)\n",
    "#logits2 = two_hidden_layers_2(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt_text](./05_images/11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
